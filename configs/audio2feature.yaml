isTrain: True
task: 'Audio2Headpose'  # Audio2Headpose, Audio2Feature, Feature2Face
gpu_ids: [0]
continue_train: False
task_block: 'audio'  # audio, face

# data info 
data_dir: '/home/yourname/lsp/data/hk_fake_38'
d3label_dir: 'label'  # all info from 3d face tracking lsp needed
original_dir: 'video_audio'  # handled video and audio (512*512, 60fps)
imgs_dir: 'imgs'  # imgs from original_dir
candidates_dir: 'candidates'
APC_dir: 'APC'  # save apc feature

# dataset
fps: 60
time_frame_length: 1  # train 240, test 1
sample_rate: 16000
audioRF_history: 60  # 'audio history receptive field length'
audioRF_future: 0  # 'audio future receptive field length'
compute_mel_online: True
frame_jump_stride: 1 
feature_encoder: 'LSTM'  # WaveNet, LSTM
frame_future: 0   # 18
predict_length: 5  # 1,5
# only_mouth: True
only_mouth: False
use_delta_pts: True
sequence_length: 240

audio_windows: 2

# APC 
audio_encoder: 'APC'
APC_audio_person: 'who_say'
APC_audio_person_version: 'who_say_vx'
re_audio_encoder: False  # when changed the scripts

APC_hidden_size: 512
APC_rnn_layers: 3
APC_residual: True
APC_frame_history: 0
audiofeature_input_channels: 80
output_size: 204   # 68*3, 29*3
enhance_mouth_scale: 1  # when infer  > 1

APC_infer:
  ckp_path: './data/APC_epoch_160.model'
  mel_dim: 80
  hidden_size: 512
  num_layers: 3
  residual: False   # training is not False 
  use_LLE: 0
  Knear: 10
  LLE_percent: 1
use_LLE: False

# LSTM 
LSTM_hidden_size: 256
LSTM_output_size: 80
LSTM_layers: 3
LSTM_dropout: False
LSTM_residual: True
LSTM_sequence_length: 60

# A2L_receptive_field: 30
A2H_receptive_field: 30


# WaveNet
A2H_wavenet_residual_layers: 7
A2H_wavenet_residual_blocks: 2
A2H_wavenet_dilation_channels: 128
A2H_wavenet_residual_channels: 128
A2H_wavenet_skip_channels: 256
A2H_wavenet_kernel_size: 2
A2H_wavenet_use_bias: True
A2H_wavenet_cond: True
A2H_wavenet_cond_channels: 512
A2H_wavenet_input_channels: 12
A2H_GMM_ncenter: 1
A2H_GMM_ndim: 12
A2H_GMM_sigma_min: 0.03

smooth_loss: 0

# weights
checkpoints: ''
ck_add_info: 'Feature2Face'  # headpose, Audio2Feature, Feature2Face

lr: 0.00001
lr_policy: 'cosine'
batch_size: 6   # audio 360, face: 6
pretrained_modelpath: '/home/yourname/lsp/data/hk_fake_38/checkpoints/Audio2Feature/Audio2Feature_196.tar'
# pretrained_modelpath: '/home/yourname/lsp/data/hk_fake_38/checkpoints/Feature2Face/Audio2Feature_56.tar'

output_dir: '/home/yourname/lsp/data/hk_fake_38/checkpoints'

train:
  resume: True
  max_epochs: 200
  checkpoint_steps: 4 
  log_steps: 10
  n_epochs: 3

infer_a: True
infer_h: True
infer_g: True
infer_file_a: '/home/yourname/lsp/data/hk_fake_38/checkpoints/Audio2Feature/Audio2Feature_196.tar'
infer_file_h: './data/hk_fake_38/checkpoints/Audio2Headpose/headpose_116.tar'
infer_file_g: './data/hk_fake_8_14/checkpoints/Feature2Face/Feature2Face_20.tar'  # 38
# infer_file_g: '/home/yourname/lsp/data/hk_fake_8_14/checkpoints/Feature2Face/Feature2Face_20.tar'  # 814
test_audio: '/home/yourname/lsp/data/hk_fake_38/video_audio/Mayun.wav'

loss_file: '/home/yourname/lsp/data/hk_fake_38/checkpoints/loss_feature2face.txt'

# ---- GAN --------
size: 'normal'
lambda_T: 10.0
lambda_F: 100.0
lambda_mask: 500.0
n_frames_D: 3
n_scales_temporal: 2
n_frames_total: 12
lambda_feat: 10.0
lambda_L1: 100.0
gan_mode: 'ls'   # ls|original|hinge
pool_size: 1
no_discriminator: 0
ndf: 64
num_D: 2
n_layers_D: 3
n_downsample_G: 8
ngf: 64
ngf_E: 16
n_downsample_E: 3
n_blocks_E: 3
no_ganFeat: True
no_vgg: False
sparse_D: True
fp16: False
img_dir: './data/hk_fake_38/imgs'
label_dir: './data/hk_fake_38/label'
candidates: './data/hk_fake_38/candidates'
frame_jump: 1
shoulder: False
loadSize: 512
gan_sample_dir: './data/hk_fake_38/g_sample'
test_gan_dir: './data/hk_fake_38/test_gan'

test_all_dir: './data/hk_fake_38/test_all'
test_train_dir: './data/hk_fake_38/test_train'
infer_dir: './data/hk_fake_38/infer_temp'
rm_infer_temp: False

Feat_smooth_sigma: 2
AMP_method: 'XYZ'  # XYZ, LowerMore, CloseSmall, XY, delta
Feat_AMPs: [1.5, 2.5, 1.5]

Headpose:
    ckp_path: './data/x'
    sigma: 0.3
    smooth: [5, 10]    # rot, trans
    AMP: [1, 1]    # rot, trans
    shoulder_AMP: 0.5

test_mode:
  headpose: True
  only_pred: False
  pred_normal: True
  mouth_smooth: True
  close_mean_pts3d_mouth: False
  open_eye: True
  save_edge: True
  only_edge: False   # only mouth and eye not generate
  enhance_mouth: False
  similarity: False   # pred landamrk find the best similarity contour in traindata
  use_fix_contour: False
  test_mouth_openrate: False
  traindata_trainaudio: False
  traindata_mean_shift: False
  pred_aligne_traindata: False
  pred_mouth_shift_by_traindata: False
